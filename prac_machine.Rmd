---
title: "practical_machine_learning"
author: "adler_jai"
date: "09/12/2020"
output: html_document
---


## Synopsis

This human activity recognition research has traditionally focused on discriminating between different activities, i.e. to predict "which" activity was performed at a specific point in time.The approach we propose for the Weight Lifting Exercises dataset is to investigate "how (well)" an activity was performed by the wearer.

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement.In this project, our is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

The goal of this project is to predict the manner in which they did the exercise. This is the `classe` variable in the training set.

## Data description

The outcome variable is `classe`, a factor variable with 5 levels.Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.
For this data set, participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in 5 different fashions:

- exactly according to the specification (Class A)
- throwing the elbows to the front (Class B)
- lifting the dumbbell only halfway (Class C)
- lowering the dumbbell only halfway (Class D)
- throwing the hips to the front (Class E)

## Initial configuration

The initial configuration consists of loading some required packages and initializing some variables.

```{r configuration, echo=TRUE, results='hide'}
#R-Packages
library(ggplot2)
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
training.file   <- 'pml-training.csv'
test.cases.file <- 'pml-testing.csv'
training.url    <- 'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
test.cases.url  <- 'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'

# Set seed for reproducability
set.seed(9999)
```

## Data processing
Here we download the requireed datasets  and processed. Some basic transformations and cleanup will be performed, so that `NA` values are omitted. And columns not used such as `user_name`, `raw_timestamp_part_1`, `raw_timestamp_part_2`, `cvtd_timestamp`, `new_window`, and  `num_window` (columns from 1 to 7) will be removed.

The `pml-training.csv` data is used to devise training and testing sets.
The `pml-test.csv` data is used to predict and answer the 20 questions based on the trained model.

```{r dataprocessing, echo=TRUE, results='hide',cache=TRUE}
# Downloading data
if(!file.exists("pml-training.csv") | !file.exists("pml-testing.csv"))
{download.file(training.url, training.file)
download.file(test.cases.url,test.cases.file )}
# Cleaning data
training   <-read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!", ""))
testing <-read.csv("pml-testing.csv", na.strings=c("NA", "#DIV/0!", ""))
training<-training[,colSums(is.na(training)) == 0]
testing <-testing[,colSums(is.na(testing)) == 0]
# Subset data
training   <-training[,-c(1:7)]
training$classe <- factor(training$classe)
testing <-testing[,-c(1:7)]
```

## DataPartition
In this section cross-validation will be performed by splitting the training data in training (75%) and testing (25%) data.

```{r , echo=TRUE, results='hide'}
subSamples <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
subTraining <- training[subSamples, ] 
subTesting <- training[-subSamples, ]
```

## Exploratory analysis
The variable `classe` contains 5 levels. The plot of the outcome variable shows the frequency of each levels in the subTraining data.

```{r , echo=TRUE}
g <- ggplot(data = subTraining,aes(classe))
g <- g+ geom_histogram(stat = "count")
g
```
The plot above shows that Level A is the most frequent classe. D appears to be the least frequent one.

## Prediction models
In this section a decision tree and random forest will be applied to the data.

### Decision tree
```{r decisiontree, echo=TRUE,cache=TRUE}
dtmod <- train(classe ~ ., data = subTraining, method="rpart")
dtmodpred <- predict(dtmod,subTesting)
dtmodconf <- confusionMatrix(dtmodpred,subTesting$classe)
dtmodconf

```


Above confusion matrix shows the errors of the prediction algorithm.
```{r}
rpart.plot(dtmod$finalModel, roundint=FALSE)
```

### Random forest
```{r randomforest, echo=TRUE,cache=TRUE}
# Fit model
rfmod <- randomForest(classe ~ ., data=subTraining, method="class")
# Perform prediction
rfpred <- predict(rfmod, subTesting)
rfmodconf <- confusionMatrix(rfpred, subTesting$classe)
rfmodconf
plot(rfmodconf$table, 
     main = paste(" Random forest  accuracy =",round(rfmodconf$overall['Accuracy'], 4)))
```


Above  confusion matrix shows the errors of the prediction algorithm.


Now we need to see how each model has predicted the validation dataset across the classifications.Know  we are comparing  Random Forest and Decision Tree model methods.
```{r}
dtmodconf$overall
rfmodconf$overall
```

## Conclusion
After checking the **Overall Statistics** data, the Random Forest model has definitely more accuracy than Decision Tree. Hence we will be selecting Random Forest model for final prediction from original test data `testing` .
### Final Prediction 
```{r}
Final_prediction <- predict(rfmod, testing,type ="class")
Final_prediction
```

